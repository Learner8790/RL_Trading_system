{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Enhanced RL Trading System - Quick Start Guide\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides a quick introduction to using the Enhanced RL Trading System for Indian equity markets.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Setup and Imports\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import yaml\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.environment import EnhancedTradingEnvironmentV2\\n\",\n",
    "    \"from src.agent import AttentionTradingAgent\\n\",\n",
    "    \"from src.trainer import ImprovedPPOTrainer\\n\",\n",
    "    \"from src.utils import set_seeds, evaluate_enhanced_agent, plot_results\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set random seeds for reproducibility\\n\",\n",
    "    \"set_seeds(42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"PyTorch version:\\\", torch.__version__)\\n\",\n",
    "    \"print(\\\"CUDA available:\\\", torch.cuda.is_available())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Load Configuration\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load configuration\\n\",\n",
    "    \"with open('../config.yaml', 'r') as f:\\n\",\n",
    "    \"    config = yaml.safe_load(f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display key configuration parameters\\n\",\n",
    "    \"print(\\\"Configuration Overview:\\\")\\n\",\n",
    "    \"print(f\\\"  Initial Cash: ₹{config['environment']['initial_cash']:,}\\\")\\n\",\n",
    "    \"print(f\\\"  Episode Length: {config['environment']['episode_length']} days\\\")\\n\",\n",
    "    \"print(f\\\"  Assets: {config['assets']['stocks']}\\\")\\n\",\n",
    "    \"print(f\\\"  Max Drawdown Limit: {config['environment']['max_drawdown_limit']*100:.0f}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Create Trading Environment\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create environment\\n\",\n",
    "    \"env = EnhancedTradingEnvironmentV2(config)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Environment created successfully!\\\")\\n\",\n",
    "    \"print(f\\\"  Number of assets: {env.n_assets}\\\")\\n\",\n",
    "    \"print(f\\\"  State dimension: {env.state_dim}\\\")\\n\",\n",
    "    \"print(f\\\"  Data points loaded: {env.data_length}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Visualize Market Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot price data for all assets\\n\",\n",
    "    \"fig, axes = plt.subplots(len(env.symbols), 1, figsize=(12, 3*len(env.symbols)))\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(env.symbols) == 1:\\n\",\n",
    "    \"    axes = [axes]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, symbol in enumerate(env.symbols):\\n\",\n",
    "    \"    prices = env.data[symbol]['close']\\n\",\n",
    "    \"    axes[i].plot(prices)\\n\",\n",
    "    \"    axes[i].set_title(f'{symbol} - Closing Prices')\\n\",\n",
    "    \"    axes[i].set_xlabel('Days')\\n\",\n",
    "    \"    axes[i].set_ylabel('Price (₹)')\\n\",\n",
    "    \"    axes[i].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Create and Initialize Agent\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create agent\\n\",\n",
    "    \"agent = AttentionTradingAgent(\\n\",\n",
    "    \"    state_dim=env.state_dim,\\n\",\n",
    "    \"    n_assets=env.n_assets,\\n\",\n",
    "    \"    hidden_dim=config['agent']['hidden_dim']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Count parameters\\n\",\n",
    "    \"total_params = sum(p.numel() for p in agent.parameters())\\n\",\n",
    "    \"trainable_params = sum(p.numel() for p in agent.parameters() if p.requires_grad)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Agent Architecture:\\\")\\n\",\n",
    "    \"print(f\\\"  Total parameters: {total_params:,}\\\")\\n\",\n",
    "    \"print(f\\\"  Trainable parameters: {trainable_params:,}\\\")\\n\",\n",
    "    \"print(f\\\"  Hidden dimension: {agent.hidden_dim}\\\")\\n\",\n",
    "    \"print(f\\\"  Number of attention heads: 8\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Test Environment Step\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test a single environment step\\n\",\n",
    "    \"state = env.reset()\\n\",\n",
    "    \"print(f\\\"Initial state shape: {state.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Initial portfolio value: ₹{env._calculate_portfolio_value():,.2f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get an action from the agent\\n\",\n",
    "    \"state_tensor = torch.FloatTensor(state).unsqueeze(0)\\n\",\n",
    "    \"actions, confidences, value = agent.get_action(state_tensor, epsilon=0.1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nAgent outputs:\\\")\\n\",\n",
    "    \"print(f\\\"  Actions: {actions} ({[['SELL', 'HOLD', 'BUY'][a] for a in actions]})\\\")\\n\",\n",
    "    \"print(f\\\"  Confidences: {[f'{c:.3f}' for c in confidences]}\\\")\\n\",\n",
    "    \"print(f\\\"  Value estimate: {value.item():.3f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Execute step\\n\",\n",
    "    \"next_state, reward, done, info = env.step(actions, confidences)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nStep results:\\\")\\n\",\n",
    "    \"print(f\\\"  Reward: {reward:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"  Done: {done}\\\")\\n\",\n",
    "    \"print(f\\\"  Trades executed: {info['trades']}\\\")\\n\",\n",
    "    \"print(f\\\"  New portfolio value: ₹{info['portfolio_value']:,.2f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Quick Training Demo\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create a trainer for a quick demo\\n\",\n",
    "    \"# Note: This is just for demonstration. Real training takes much longer!\\n\",\n",
    "    \"demo_config = config['training'].copy()\\n\",\n",
    "    \"demo_config['n_epochs'] = 3  # Reduced for demo\\n\",\n",
    "    \"demo_config['n_steps'] = 256  # Reduced for demo\\n\",\n",
    "    \"\\n\",\n",
    "    \"trainer = ImprovedPPOTrainer(\\n\",\n",
    "    \"    env=env,\\n\",\n",
    "    \"    agent=agent,\\n\",\n",
    "    \"    config=demo_config\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Training for 10 episodes (demo only)...\\\")\\n\",\n",
    "    \"trainer.train(n_episodes=10)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nDemo training completed!\\\")\\n\",\n",
    "    \"print(f\\\"Episodes completed: {len(trainer.episode_rewards)}\\\")\\n\",\n",
    "    \"print(f\\\"Average reward: {np.mean(trainer.episode_rewards):.2f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Evaluate Agent Performance\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate the agent (even though it's barely trained)\\n\",\n",
    "    \"print(\\\"Evaluating agent performance...\\\")\\n\",\n",
    "    \"eval_results = evaluate_enhanced_agent(\\n\",\n",
    "    \"    env=env,\\n\",\n",
    "    \"    agent=agent,\\n\",\n",
    "    \"    n_episodes=5,  # Just a few episodes for demo\\n\",\n",
    "    \"    epsilon=0.05\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display results\\n\",\n",
    "    \"print(\\\"\\\\nEvaluation Results:\\\")\\n\",\n",
    "    \"print(f\\\"  Average Return: {eval_results['net_return'].mean():.2f}%\\\")\\n\",\n",
    "    \"print(f\\\"  Average Sharpe: {eval_results['sharpe_ratio'].mean():.2f}\\\")\\n\",\n",
    "    \"print(f\\\"  Average Win Rate: {eval_results['win_rate'].mean():.1%}\\\")\\n\",\n",
    "    \"print(f\\\"  Average Trades: {eval_results['trades'].mean():.1f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Visualize Results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Simple visualization of results\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(12, 8))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Returns distribution\\n\",\n",
    "    \"axes[0, 0].hist(eval_results['net_return'], bins=20, alpha=0.7, color='blue')\\n\",\n",
    "    \"axes[0, 0].axvline(eval_results['net_return'].mean(), color='red', linestyle='--')\\n\",\n",
    "    \"axes[0, 0].set_title('Returns Distribution')\\n\",\n",
    "    \"axes[0, 0].set_xlabel('Return (%)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sharpe ratios\\n\",\n",
    "    \"axes[0, 1].plot(eval_results['sharpe_ratio'], marker='o')\\n\",\n",
    "    \"axes[0, 1].axhline(eval_results['sharpe_ratio'].mean(), color='red', linestyle='--')\\n\",\n",
    "    \"axes[0, 1].set_title('Sharpe Ratio by Episode')\\n\",\n",
    "    \"axes[0, 1].set_xlabel('Episode')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Win rate vs returns\\n\",\n",
    "    \"axes[1, 0].scatter(eval_results['win_rate']*100, eval_results['net_return'])\\n\",\n",
    "    \"axes[1, 0].set_title('Win Rate vs Returns')\\n\",\n",
    "    \"axes[1, 0].set_xlabel('Win Rate (%)')\\n\",\n",
    "    \"axes[1, 0].set_ylabel('Return (%)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Confidence levels\\n\",\n",
    "    \"axes[1, 1].hist(eval_results['avg_confidence'], bins=20, alpha=0.7, color='green')\\n\",\n",
    "    \"axes[1, 1].set_title('Average Confidence Distribution')\\n\",\n",
    "    \"axes[1, 1].set_xlabel('Confidence')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"This was just a quick introduction! For real trading performance:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Full Training**: Train for 1500+ episodes (see `train_agent.py`)\\n\",\n",
    "    \"2. **Hyperparameter Tuning**: Adjust learning rates, network architecture\\n\",\n",
    "    \"3. **Data Enhancement**: Add more stocks, longer history\\n\",\n",
    "    \"4. **Advanced Features**: Implement market regime detection, correlation analysis\\n\",\n",
    "    \"5. **Backtesting**: Run comprehensive backtests on out-of-sample data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Check the full documentation and examples for more details!\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
